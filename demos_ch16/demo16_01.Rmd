---
title: "Data science per psicologi - demo 16.01"
author: "Corrado Caudek"
date: "`r format(Sys.Date())`"
output:
  html_document:
    theme: readable
    highlight: pygments
    code_download: true
---

<style type="text/css">
  body{
  font-size: 13pt;
}
code.r{
  font-size: 13pt;
  font-family: 'Inconsolata';
}
.custom-inline {
  font-size: 13pt;
  font-family: 'Inconsolata';
}
</style>


```{r}
suppressPackageStartupMessages({
  library("here")
  library("tidyverse")
  library("scales")
  library("bayesplot")
  library("distrEx")
})

theme_set(bayesplot::theme_default(base_size = 12))
bayesplot::color_scheme_set("gray")
set.seed(84735)

knitr::opts_chunk$set(
  collapse = TRUE,
  tidy = 'styler',
  fig.width = 6,
  fig.asp = 0.618 # 1 / phi
)
```

# Lo schema beta-binomiale

Per una distribuzione a priori $\mbox{Beta}(\alpha, \beta)$ e una verosimiglianza $\mbox{Bin}(n, y \mid \theta)$, la distribuzione a posteriori del parametro $\theta$ è una distribuzione $\mbox{Beta}(\alpha + y, \beta + n - y)$.

## Un esempio concreto

Per fare un esempio, consideriamo i dati di Zetsche et al. (2019) nei quali abbiamo osservato 23 successi in 30 prove.

Nel tutorial che abbiamo considerato in precedenza, abbiamo usato una $\mbox{Beta}(\alpha = 23.4, \beta = 6.6)$ quale distribuzione a priori.

Per le proprietà delle distribuzioni coniugate, sappiamo che la distribuzione a posteriori per il parametro $\theta$ (probabilità di successo in una singola prova) sarà una $\mbox{Beta}(\alpha = 23.4 + 23, \beta = 6.6 + 30 - 23)$, ovvero una $\mbox{Beta}(\alpha = 46.4, \beta = 13.6)$. 

### Le funzioni del pacchetto `bayesrules`

Questo risultato si ottiene facilmente usando la funzione `bayesrules::summarize_beta_binomial()`:

```{r}
bayesrules:::summarize_beta_binomial(
  alpha = 23.4, beta = 6.6, y = 23, n = 30
)
```

Usando la funzione `bayesrules::plot_beta_binomial`, possiamo ottenere un grafico della distribuzion a priori, della verosimiglianza e della distribuzione a posteriori per il parametro $\theta$:

```{r}
 bayesrules::plot_beta_binomial(
  alpha = 23.4, beta = 6.6, y = 23, n = 30
)
```

Con questa scelta della distribuzione a priori, le tre funzioni sono molto simili tra loro.


## Approssimazione numerica

Svolgiamo i calcoli mediante il metodo dell'approssimazione numerica. Considerando solo 20 valori per il parametro $\theta$, otteniamo la  distribuzione a posteriori nel modo seguente. Iniziamo a definire le costanti che useremo nella simulazione.

```{r}
n <- 20
theta <- seq(0, 1, length.out = n)
alpha <- 23.4
beta <- 6.6
```

Calcoliamo la distribuzione a priori per $\theta$ non normalizzata:

```{r}
fx <- dbeta(theta, alpha, beta)
```

Normalizziamo:

```{r}
prior <- fx / sum(fx)
```

Calcoliamo la verosimiglianza non normalizzata:

```{r}
like <- dbinom(23, 30, theta)
```

Normalizziamo:

```{r}
like_n <- like / sum(like)
```

Calcoliamo la distribuzione a posteriori $p(\theta \mid y)$ non normalizzata:

```{r}
post_distr <- prior * like
```

Normalizziamo

```{r}
post <- post_distr / sum(post_distr)
```

Creo ora un grafico della distribuzione a posteriori $p(\theta \mid y)$:

```{r}
tibble(theta, post) %>% 
  ggplot(aes(x = theta, y = post)) +
  geom_point(size = 3) +
  geom_linerange(aes(x = theta, ymax = post, ymin = 0)) 
```

Alla soluzione ottenuta per via numerica (rappresentata nella figura precedente), sovrappongo ora la distribuzione Beta di parametri $\alpha = 23.4 + 23 = 46.4$ e $\beta = 6.6 + 30 - 23 = 13.6$. I valori della $\mbox{Beta}(46.4, 13.6)$ sono rappresentati da una spezzata dato che abbiamo solo 20 valori $\theta$.

```{r}
beta_post <- dbeta(theta, 46.4, 13.6) / sum(dbeta(theta, 46.4, 13.6))
tibble(theta, post) %>% 
  ggplot(aes(x = theta, y = post)) +
  geom_point(size = 3) +
  geom_linerange(aes(x = theta, ymax = post, ymin = 0)) +
  geom_line(aes(x = theta, y = beta_post))
```

Possiamo concludere dicendo che l'approssimazione numerica riproduce perfettamente il risultato ottenuto per via analitica. Ovviamente, usare solo 20 punti per $\theta$ ha un senso solo 'didattico', ovvero, per spiegare la procedura da seguire. Per qualunque scopo concreto si useranno più punti.


## Inferenza bayesiana

L'inferenza bayesiana procede mediante la verifica di ipotesi bayesiana e mediante il calcolo degli intervalli di credibilità.

### Verifica di ipotesi bayesiana

Una volta ottenuta la distribuzione a posteriori per il parametro ignoto $\theta$, è facile rispondere a domande del tipo: qual è la probabilità che $\theta$ assuma un valore maggiore di 0.90? Nel caso presente, la risposta a questa domanda è:

```{r}
1 - pbeta(0.9, 46.4, 13.6)
```

In maniera equivalente, possiamo trovare la stessa risposta usando la funzione `beta_area()`:

```{r}
ProbBayes::beta_area(lo = 0.9, hi = 1.0, shape_par = c(46.4, 13.6))
```


### Intervalli di credibilità

Qual è l'intervallo della distribuzione a posteriori che include il 50% dell'area? Ovvero, qual è l'intervallo che ha la probabilità a posteriori del 50% di contenere il vero valore del parametro $\theta$?

```{r}
ProbBayes::beta_interval(0.5, c(46.4, 13.6))
```

## Informazioni sulla sessione di lavoro

```{r}
utils::sessionInfo()
```
