---
title: "Data science per psicologi - demo 14.02"
author: "Corrado Caudek"
date: "`r format(Sys.Date())`"
output:
  html_document:
    theme: readable
    highlight: pygments
    code_download: true
---

<style type="text/css">
  body{
  font-size: 13pt;
}
code.r{
  font-size: 13pt;
  font-family: 'Inconsolata';
}
.custom-inline {
  font-size: 13pt;
  font-family: 'Inconsolata';
}
</style>


```{r}
suppressPackageStartupMessages({
  library("here")
  library("tidyverse")
  library("bayesplot")
  library("purrr")
  library("ggformula")
})

theme_set(bayesplot::theme_default(base_size = 12))
bayesplot::color_scheme_set("gray")
set.seed(84735)

knitr::opts_chunk$set(
  collapse = TRUE,
  tidy = 'styler',
  fig.width = 6,
  fig.asp = 0.618 # 1 / phi
)
```

# Aggiornamento bayesiano -- versione 2

Ripropongo qui il calcolo della distribuzione a posteriori per il caso di un campione di 23 successi in 30 prove Bernoulliane iid che è stato discusso nel demo14_01. L'unica novità è che svolgeremo ora i calcoli con $\mathsf{R}$ in maniera più semplice. Tutto ciò di cui abbiamo bisogno è l'istruzione che troviamo alla fine di questo tutorial. Ma la costruisco qui "passo passo".

Inizio con il definire i dati.

```{r}
y <- 23
n <- 30
```

Per creare la griglia dei valori theta, uso ora la funzione `expand.grid()`. Nel caso di 11 valori soltanto, per esempio, otteniamo il risultato seguente.

```{r}
coins_grid <- expand.grid(theta = seq(0, 1, length.out=11))
coins_grid
```

Creo una griglia di 1000 punti.

```{r}
coins_grid <- 
  expand.grid(
    theta = seq(0, 1, length.out=1000)
  ) 
```

Per ciascuno di questi valori theta voglio calcolare la verosimiglianza. Per fare ciò devo prendere ciascun valore theta e passarlo alla funzione `dbinom()` nella quale tengo fissi i dati, ovvero `dbinom(x = y, size = n, theta)`, laddove `theta` è il valore che voglio passare alla funzione. Per fare questo, ovvero, per applicare una funzione (nel nostro caso, `dbinom()`) a ciascun elemento di un vettore, uso la funzione `purrr::map_dbl()` che fa esattamente quello che ho detto sopra, ovvero applica la funzione specificata a ciascun elemento di un vettore. La sintassi è indicata sotto. Ho usato `mutate()` per aggiungere la colonna `likelihood` al DataFrame `coins_grid`.

```{r}
coins_grid <- 
  expand.grid(
    theta = seq(0, 1, length.out=100)
  ) %>%
  mutate(
    likelihood = map_dbl(theta, ~ dbinom(x = y, size = n, .x))
  )
```

Guardiamo il risultato ottenuto:

```{r}
coins_grid %>% 
  head()
```

Per esempio, il valore della variabile `likelihood` quando `theta` è uguale a 0.05050505 è ottenuto nel modo seguente.

```{r}
dbinom(23, 30, 0.05050505)
```

La stessa procedura è applicata a tutti i valori della variabile `theta`.

Aggiungo ora a una colonna che, per ciascun valore `theta` riporta l'ordinata della distribuzione a priori, che nel nostro caso è una Beta(2, 10).

```{r}
coins_grid <- 
  expand.grid(
    theta = seq(0, 1, length.out=100)
  ) %>%
  mutate(
    prior = dbeta(theta, 2, 10),
    likelihood = map_dbl(theta, ~ dbinom(x = y, size = n, .x))
  )
```

I primi valori del DataFrame sono i seguenti.

```{r}
coins_grid %>% 
  head()
```

Avendo discretizzato `theta`, la somma dei valori delle ordinate così ottenute non sarà 1.

```{r}
sum(coins_grid$prior)
```

Dunque normalizzo.

```{r}
coins_grid <- 
  expand.grid(
    theta = seq(0, 1, length.out=100)
  ) %>%
  mutate(
    prior = dbeta(theta, 2, 10),
    prior1 = prior / sum(prior),
    likelihood = map_dbl(theta, ~ dbinom(x = y, size = n, .x))
  )
```

Verifico.

```{r}
coins_grid$prior1 %>% 
  sum()
```

Ora è facile calcolare la distribuzione (discretizzata) a posteriori e normalizzarla.

```{r}
coins_grid <- 
  expand.grid(
    theta = seq(0, 1, length.out=100)
  ) %>%
  mutate(
    prior = dbeta(theta, 2, 10),
    prior1 = prior / sum(prior),
    likelihood = map_dbl(theta, ~ dbinom(x = y, size = n, .x)),
    posterior0 = prior * likelihood,
    posterior = posterior0 / sum(posterior0)
  )
```

```{r}
coins_grid %>% 
  head()
```

Verifico.

```{r}
coins_grid$posterior %>% 
  sum()
```

Per creare un grafico ho anche bisogno della verosimiglianza normalizzata (altrimenti le aree sottese alle varie curve sono troppo diverse). L'istruzione $\mathsf{R}$ di cui ho bisogno per svolgere tutti i calcoli dell'approssimazione basata su griglia della distribuzione a posteriori è la seguente.

```{r}
coins_grid <- 
  expand.grid(
    theta = seq(0, 1, length.out=100)
  ) %>%
  mutate(
    prior = dbeta(theta, 2, 10),
    prior1 = prior / sum(prior),
    likelihood = map_dbl(theta, ~ dbinom(x = y, size = n, .x)),
    likelihood1 = likelihood / sum(likelihood),
    posterior0 = prior * likelihood,
    posterior = posterior0 / sum(posterior0)
  )
```

Un grafico della distribuzione a priori normalizzata, della verosimiglianza normalizzata e della distribuzione a posteriori normalizzata si ottiene nel modo seguente.

```{r}
gf_area(prior1 ~ theta, data = coins_grid, alpha = 0.3) %>%
  gf_area(likelihood1 ~ theta, data = coins_grid, alpha = 0.3, fill = "green") %>%
  gf_area(posterior ~ theta, data = coins_grid, alpha = 0.3, fill = "steelblue")
```

Abbiamo qui usato l'approssimazione numerica basata su griglia per trovare la distribuzione a posteriori del caso beta-binomiale. Sappiamo lo schema beta-binomiale ci offre una soluzione analitica. Si noti che l'approssimazione numerica basata su griglia può essere usata in qualsiasi caso, anche quando non conosciamo (e soprattutto quando non conosciamo) la soluzione analitica.

## Informazioni sulla sessione di lavoro

```{r}
utils::sessionInfo()
```


