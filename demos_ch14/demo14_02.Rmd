---
title: "Data science per psicologi - demo 14.02"
author: "Corrado Caudek"
date: "`r format(Sys.Date())`"
output:
  html_document:
    theme: readable
    highlight: pygments
    code_download: true
---

```{r}
suppressPackageStartupMessages({
  library("here")
  library("tidyverse")
  library("scales")
  library("bayesplot")
  library("distrEx")
})

theme_set(bayesplot::theme_default(base_size = 12))
bayesplot::color_scheme_set("gray")
set.seed(84735)

knitr::opts_chunk$set(
  collapse = TRUE,
  tidy = 'styler',
  fig.width = 6,
  fig.asp = 0.618 # 1 / phi
)
```

<style type="text/css">
  body{
  font-size: 13pt;
}
code.r{
  font-size: 13pt;
  font-family: 'Inconsolata';
}
.custom-inline {
  font-size: 13pt;
  font-family: 'Inconsolata';
}
</style>

# Funzione di verosimiglianza Gaussiana

La funzione di verosmiglianza è la funzione di massa o di densità di probabilità dei dati $y$ vista come una funzione del parametro sconosciuto (o dei parametri sconosciuti) $\theta$. Nel tutorial precedente abbiamo visto come costruire la funzione di verosimiglianza nel caso di un modello Binomiale. Consideriamo qui il modello gaussiano:

$$
{\displaystyle f(x)={\frac {1}{\sigma {\sqrt {2\pi }}}}e^{-{\frac {1}{2}}\left({\frac {x-\mu }{\sigma }}\right)^{2}}}.
$$

Ci poniamo il problema di costruire la funzione di verosimiglianza per questa funzione di densità di probabilità. 

## Una singola osservazione

Consideriamo prima il caso in cui i dati corrispondono ad una singola osservazione $x$. La formula precedente dipende dai parametri $\mu$ e $\sigma$ e dai dati $x$. Per costruire la funzione di verosimiglianza, dobbiamo dunque inserire nella formula precedente un singolo valore $x$. In output abbiamo il risultato che si ottiene variando, nella funzione, i valori di due parametri: $\mu$ e $\sigma$. 

Per semplicità, consideriamo il caso in cui si ipotizza $\sigma$ noto e uguale a 15. Poniamo $x = 114$.

```{r}
x <- 114
```

Esamineremo qui l'andamento della funzione nell'intervallo di valori $\mu$ compreso tra 70 e 160:

```{r}
mu <- seq(70, 160, length.out = 1e3)
```

La formula della distribuzione Gaussiana è implementata in $\mathsf{R}$ nella funzione `dnorm()`. La funzione `dnorm()` ha tre argomenti:

- il valore $x$ (o il vettore $x$),
- la media, ovvero il parametro $\mu$,
- la deviazione standard, ovvero il parametro $\sigma$.

Come nel caso della Binomiale, anche ora, per calcolare la funzione di verosimiglianza, teniamo costante i dati -- nel caso presente, il singolo valore $x = 114$, e facciamo variare il valore dei parametri -- qui, solo $\mu$, dato che il parametro $\sigma$ è assunto noto, $\sigma = 15$. 

Nella presente simulazione consideriamo 1000 possibile valori del parametro $\mu \in [70, 160]$. Applichiamo dunque 1000 volte la formula della densità Gaussiana, una volta per ciascuno dei 1000 possibili valori $\mu$, tenendo costanti gli altri valori nella formula, ovvero $x = 114$ e $\sigma = 15$. Otteniamo così 1000 punti -- ovvero, 1000 coppie di valori $\mu$ e $f(\mu)$. La curva che interpola tali punti è la funzione di verosimiglianza.

```{r}
f_mu <- dnorm(x, mean = mu, sd = 15)
```

Si noti che la funzione di verosimiglianza ha la forma della distribuzione Gaussiana. Nel caso di una singola osservazione (ma solo in questo caso), ha anche un'area unitaria: 

```{r}
integrand <- function(mu) {
  x = 114
  sigma = 15
  dnorm(x, mu, sigma)
}
integrate(integrand, lower = -10000, upper = 10000)
```

La moda di tale funzione è 114:

```{r}
tibble(mu, f_mu) %>% 
  ggplot(
    aes(x = mu, y = f_mu)
  ) +
    geom_line() +
    vline_at(114, color = "red", linetype="dashed") +
      labs(
      y = "Verosimiglianza",
      x = c("Parametro \u03BC")
    ) 
```


## Un campione di osservazioni

Consideriamo ora il caso di 30 osservazioni indipendenti iid, ciascuna delle quali può essere considerata come la realizzazione di una variabile casuale Gaussiana di media comune sconosciuta e di deviazione standard pari a 15.

```{r}
n <- 30 
true_sigma <- 15 
```

Generiamo un campione di dati assumendo che il valore ignoto di $\mu$ sia pari a 100:

```{r}
set.seed(123)
true_mu <- 100 
x <- rnorm(n, true_mu, true_sigma)
x
```

Supponiamo che questi siano i dati osservati.

Costruiamo ora la funzione di verosimiglianza. 

Abbiamo visto in precedenza che, nel caso di due variabili casuali $X_1$ e $X_2$, è la probabilità congiunta è: 

$$
P(X_1, X_2) = P(X_1) P(X_2 \mid X_1).
$$

Se le due variabili casuali sono indipendenti, abbiamo semplicemente 

$$
P(X_1, X_2) = P(X_1) P(X_2).
$$

Possiamo generalizzare tale risultato al caso delle distribuzioni di densità di probabilità. In particolare, nel caso di $n$ v.c. iid, cascuna distribuita come $\mathcal{N}(\mu, \sigma)$, avremo che

$$
p(X_1, \dots, X_n ; \mu, \sigma) = \prod p(X_i; \mu, \sigma).
$$

Dato che fare il prodotto di 30 valori minori di 1 produce un numero molto piccolo, calcoliamo invece la *log-verosimiglianza*. Il logaritmo della funzione di densità congiunta è dato da una somma:

$$
\log p(X_1, \dots, X_n ; \mu, \sigma) = \log \Big( \prod p(X_i; \mu, \sigma)\Big) =  \sum \log p(X_i; \mu, \sigma).
$$

Nella funzione di densità congiunta, facciamo nuovamente variare il valore dei parametri (in questo caso, solo $\mu$)  e teniamo costante tutto il resto (ovvero, i dati e $\sigma$). Così facendo otteniamo la funzione di log-verosmiglianza che in $\mathsf{R}$ si può scrivere così:

```{r}
log_likelihood <- function(x, mu, sigma = true_sigma) {
  sum(dnorm(x, mu, sigma, log = TRUE))
}
```

Nel caso presente, i dati sono:

```{r}
x
```

Nella simulazione, per generare la figura consideriamo valori $\mu \in [70, 130]$:

```{r}
nrep <- 1e5
mu <- seq(70, 130, length.out = nrep)
```

Per ciascuno di questi possibili valori del parametro $\mu$ calcoliamo il valore della funzione congiunta di verosimiglianza usando tutte le 30 osservazioni del campione. Salviamo i risultati nel vettore `ll`:

```{r}
ll <- rep(NA, nrep)
for (i in 1:nrep) {
  ll[i] <- log_likelihood(x, mu[i], true_sigma)
}
```

Possiamo ora generare un grafico della funzione di log-verosimiglianza:

```{r}
tibble(mu, ll) %>% 
  ggplot(
    aes(x = mu, y = ll)
  ) +
    geom_line() +
    vline_at(mean(x), color = "red", linetype="dashed") +
    labs(
      y = "Log-verosimiglianza",
      x = c("Parametro \u03BC")
    ) 
```

## Stima di massima verosimiglianza

Troviamo ora la stima di massima verosimiglianza, ovvero il valore del paraemtro che massimizza la funzione di (log-) verosimiglianza:

$$
\hat{\mu} = \mbox{arg max}_{\mu} \, \ell (x \mid \mu).
$$

```{r}
mu[which.max(ll)]
```

Sappiamo che la stima di massima verosimiglianza coincide con la media del campione. Verifichiamo:

```{r}
mean(x)
```

L'approssimazione deriva dal fatto che abbiamo utilizzato un numero finito di punti.


## Informazioni sulla sessione di lavoro

```{r}
utils::sessionInfo()
```


