---
title: "Data science per psicologi - demo 19.02"
author: "Corrado Caudek"
date: "`r format(Sys.Date())`"
output:
  html_document:
    theme: readable
    highlight: pygments
    code_download: true
---

<style type="text/css">
  body{
  font-size: 13pt;
}
code.r{
  font-size: 13pt;
  font-family: 'Inconsolata';
}
.custom-inline {
  font-size: 13pt;
  font-family: 'Inconsolata';
}
</style>

```{r}
suppressPackageStartupMessages({
  library("here")
  library("tidyverse")
  library("bayesplot")
  library("rstan")
  library("cmdstanr")
  library("posterior")
})

rstan_options(auto_write = TRUE) # avoid recompilation of models
options(mc.cores = parallel::detectCores()) # parallelize across all CPUs
Sys.setenv(LOCAL_CPPFLAGS = "-march=native") # improve execution time

theme_set(bayesplot::theme_default(base_size = 12))
bayesplot::color_scheme_set("gray")
set.seed(84735)

knitr::opts_chunk$set(
  collapse = TRUE,
  tidy = 'styler',
  fig.width = 6,
  fig.asp = 0.618 # 1 / phi
)
```

# Modello beta-binomiale in Stan

In questo demo ci poniamo il problema di implementare il modello beta-binomiale usando Stan.

Riprendiamo l'esempio che abbiamo discusso in precedenza, ovvero quello in cui la verosimiglianza è binomiale e la distribuzione a priori è una Beta. I dati corrispondono a 23 "successi" in 30 prove. 

La distribuzione a priori è una Beta(2, 10).

```{r}
bayesrules::plot_beta(alpha = 2, beta = 10, mean = TRUE, mode = TRUE)
```

## I dati

Inseriamo i dati in una lista così come richiesto da Stan:

```{r}
data_list <- list(
  N = 30,
  y = c(rep(1, 23), rep(0, 7))
)
```

Si noti che qui stiamo usando una codifica dei dati (il "tipo" dei dati) che non abbiamo usato finora. Finora ci siamo occupati di vettori, ovvero sequenze di elementi tutti dello stesso tipo (per es., numeri, o stringhe, ma non entrambi), oppure `data.frame`, ovvero una organizzazione tabulare (in righe e colonne) dei dati nella quale le colonne (le "variabili") possono corrispondere a tipi diveri: una colonna può essere numerica, un'altra colonna può contenere valori alfanumerici (stringhe). L'unico vincolo in un DataFrame è che tutte le colonne devono contenere lo stesso numero di elementi.

Un ulteriore tipo di dato supportato da R è il tipo `list`. Una lista è una sequenza di elementi che, a differenza di vettori, matrici ed array, possono avere tutti tipo diverso. Ad esempio, il primo elemento di una lista può essere un numero, il secondo elemento della lista può essere un vettore, il terzo elemento della lista può essere un DataFrame: ciascun elemento della lista può avere tipo diverso e può anche essere costituito da un diverso numero di elementi.

Una lista si crea con il costruttore `list()` i cui argomenti di `list()` sono gli elementi della lista. 

Nel caso presente, il primo elemento della lista è uno scalare chiamato `N`; il secondo elemento della lista è un vettore di 30 elementi, chiamato `y`.  Alla lista che abbiamo creato abbiamo assegnato il nome di `data_list`.

```{r}
data_list
```

Per estrarre da una lista l'elemento i-esimo usiamo la sintassi `[[i]]`. Per esempio, il primo elemento di `data_list` è

```{r}
data_list[[1]]
```

Il secondo elemento di `data_list` è

```{r}
data_list[[2]]
```

In alternativa, possiamo anche usare il nome dell'elemento della lista

```{r}
data_list$y
```

Questa sintassi ci fa capire che il tipo `data.frame` è una lista.


## Definizione del modello in Stan

Stan è un linguaggio probabilistico che consente di generare campioni casuali da una distribuzione a posteriori. La specificazione del modello in Stan, per il caso presente, è fornita qui sotto. Si noti l'organizzazione in "blocchi". Ogni blocco ha un nome (i blocchi possibili sono `data`, `parameters`, `model` e altri) seguito da una parentesi graffa.

```{r}
model_string <- "
data {
  int<lower=0> N;
  array[N] int<lower=0, upper=1> y;
}
parameters {
  real<lower=0, upper=1> theta;
}
model {
  theta ~ beta(2, 10);
  y ~ bernoulli(theta);
}
"
```

### Blocco `data`

Il primo blocco (`data`) definisce il tipo di dati che verranno usati nel modello. I nomi dei dati qui elencati, ovvero `N` e `y` devono corrispondere ai nomi utilizzati nella lista di dati che verrà utilizzata in input. Infatti, in `data_list` ci sono due elementi (l'ordine è irrilevante): un elemento chiamato `N` e un elemento chiamato `y`. 

Nel blocco `data` è anche necessario chiarire il tipo dei dati.  

L'espressione `int<lower=0> N;` significa che l'oggetto `N` è di tipo `int`, ovvero che è un numero naturale (0, 1, 2, ...) il cui valore minimo `<lower>` è uguale a 0 -- non ha ovviamente senso una numerosità campionaria minore di 0.

Il codice funzionerà anche se non specifichiamo `<lower=0>`, ma quando abbiamo informazioni sui vincoli che devono essere soddisfatti dai dati è meglio renderli espliciti perché, in questo modo, se i vincoli vengono violati (es., specifichiamo una numerosità campionaria minore di 0), l'esecuzione del codice verrà immediatamente interrotta e il messaggio d'errore ci dirà che i dati in input non soddisfano i vincoli richiesti.

L'istruzione `array[N] int<lower=0, upper=1> y;` indica che `y` (la sequenza di prove Bernoulliane dell'esperimento) è un vettore. Infatti `array[N]` significa che `y` è un array (vettore) costituito da `N` elementi, laddove `N` è specificato dall'istruzione precedente.

Anche qui specifichiamo il vincolo che i dati `y` devono soddisfare: gli elementi di `y` non possono assumere valori minori di 0 o maggiori di 1 -- infatti, ciascun elemento può solo assumere i valori 0 oppure 1.

Si noti che ogni riga del blocco `data` (e di qualsiasi blocco) termina con un `;`. Questo è un aspetto necessario della sintassi di Stan; se violiamo questo requisito, il codice ci fornirà un errore.

Il blocco `data` si conclude quando viene chiusa la parantesi graffa. Dopo la parentesi graffa non è necessario il punto e virgola.

### Blocco `parameters`

Il blocco `parameters` deve elencare i parametri che vogliamo stimare. Il linguaggio probabilistico Stan (e tutti gli altri linguaggi probabilistici) consente di generare un campione casuale tratto dalla distribuzione a posteriori dei parametri indicati. 

Nel caso del modello beta-binomiale che stiamo discutendo, l'unico parametro ignoto è $\theta$, ovvero la probabilità di successo in una singola prova Bernoulliana.

L'istruzione `real<lower=0, upper=1> theta;` specifica che il parametro di interesse è chiamato `theta`. Ci dice inoltre che `theta` è un numero reale compreso nell'intervallo [0, 1]. Ciò significa che `theta` può assumere un valore qualsiasi nell'intervallo indicato.

### Blocco `model`

Il blocco `model` contiene due righe. La prima riga definisce la distribuzione a priori che vogliamo assegnare al parametro `theta`. L'istruzione `theta ~ beta(2, 10);` ci diche che la distribuzione a priori che abbiamo imposto su `theta` è una Beta(2, 10). In Stan, per fare riferimento alla distribuzione Beta usiamo la funzione `beta()` la quale prende due parametri: alpha (nel nostro caso, 2) e beta (nel nostro caso, 10). Quindi, l'istruzione `theta ~ beta(2, 10);` corrisponde alla specificazione della distribuzione a priori per $\theta$ che, in precedenza, abbiamo indicato con 

$$
\theta \sim \mbox{Beta}(2, 10).
$$

La riga successiva specifica la verosimiglianza, ovvero $p(y \mid \theta)$. Nel caso presente, la verosimiglianza è Binomiale, ovvero 

$$
{\displaystyle f(y,n,p)=\Pr(y;n,p)=\Pr(X=y)={\binom {n}{y}}\theta^{y}(1-\theta)^{n-y}},
$$

espressa in funzione di $\theta$, ovvero

$$
y \sim \mbox{Binom}(n, \theta).
$$

In linguaggio Stan, scriviamo la verosimiglianza come `y ~ bernoulli(theta)`, il che significa che ciascun elemento del vettore `y` è una variabile casuale Bernoulliana con probabilità (ignota) di successo `theta`. Ciò significa dire che il numero dei successi in $n$ prove è una variabile casuale Binomiale. Sono possibili specificazioni diverse (ma equivalenti) della verosimiglianza, ma questa è la più semplice.

## Salvare il modello Stan in un file

Tutto il modello Stan è racchiuso tra virgolette doppie, il che significa che sarà rappresentato come una serie di stringhe. A tale modello abbiamo assegnato il nome di `model_string`.

Con la funzione `writeLines()` salviamo il modello (che è un file di testo) in un file chiamato `oneprop_1.stan`. Il primo argomento di `writeLines()` specifica l'oggetto $\mathsf{R}$ che contiene le istruzioni Stan. Il secondo argomento specifica il nome del file che vogliamo creare. Si noti che il nome del file deve avere l'estensione `.stan`. Per l'esempio presente, ho creato una cartella chiamata `code`; il secondo argomento di `writeLines()` specifica che il file `.stan` deve essere salvato in quella cartella.

```{r}
writeLines(model_string, con = "code/oneprop_1.stan")
```

Per potere eseguire il campionamento MCMC è necessario leggere il file che abbiamo creato e nel quale abbiamo salvato il codice Stan. Con la funzione `file.path()` specifichiamo la posizione dove è stato salvato il file che abbiamo creato.

```{r}
file <- file.path("code", "oneprop_1.stan")
```

L'oggetto `file` non è nient'altro che l'indirizzo del file di interesse in relazione alla working directory.

```{r}
file
```

## Compilare il modello

La funzione `cmdstan_model()` esegue due operazioni:

- traduce il programma scritto in linguaggio Stan in linguaggio C++,
- il compilatore C++ compila la sorgente C++ che è stata creata e la collega alle librerie Stan.

Viene così creato un programma eseguibile che consente di eseguire il campionamento MCMC. Salvo l'eseguibile così creato assegnandoli il nome `mod`.

```{r}
mod <- cmdstan_model(file)
```

## Eseguire il campionamento MCMC

Possiamo ora eseguire il campionamento MCMC usando `mod$sample()`. Specifichiamo l'argomento `data = data_list` così da fornire in input la lista che contiene i nostri dati. L'argomento `iter_sampling` specifica 4000 iterazioni, ovvero richiede che la catena di Markov sia costituita da 4000 passi. L'argomento `iter_warmup` specifica che i primi 2000 valori della catena saranno esclusi. L'argomento `seed` specifica il seed, per la riproducibilità dei risultati. L'argomento `chanins` specifica il numero di catene di Markov che verranno costruite in parallelo, partendo da posizioni iniziali diverse e scelte in maniera casuale. L'argomento `refresh = 0` richiede che non venga stampato un messaggio che mostra la proporzione di avanzamento della costruzione della catena di Markov. L'argomento `thin = 1` specifica che verranno salvati tutti i punti della catena di Markov.

Ricordo che una catena di Markov è una sequenza di valori che vengono generati in un modo simile a quello che abbiamo descritto quando abbiamo presentato l'algoritmo di Metropolis. Per generare questa sequenza di valori, Stan non usa l'algoritmo di Metropolis, ma una sua variante. La differenza fondamentale tra l'algoritmo di Metropolis e l'algoritmo usato da Stan (che si chiama campionamento hamiltoniano, *Hamiltonian sampling*) è che l'algoritmo usato da Stan è più efficiente dell'algoritmo di Metropolis, ovvero converge alla vera distribuzione a posteriori dei parametri "più velocemente", ovvero con un numero minore di passi. A parte questa differenza, i risultati che si ottengono con i due algoritmi sono equivalenti.

Nella seguente istruzione salviamo l'output di `mod$sample()` in un oggetto chiamato `fit`.

```{r, message = FALSE, warning=FALSE, results='hide'}
fit <- mod$sample(
  data = data_list,
  iter_sampling = 4000L,
  iter_warmup = 2000L,
  seed = 84735,
  chains = 4L,
  refresh = 0,
  thin = 1
)
```

Si notino i messaggi che vengono forniti alla conclusione del campionamento MCMC. In particolare, `All 4 chains finished successfully.` ci dice che il campionamento è andato a buon fine, nel senso che non ci sono stati problemi di convergenza. Se non otteniamo questo messaggio questo vuol dire che non c'è stata convergenza, ovvero che i valori che sono stati generati *non* costituiscono un campione casuale della distribuzione a posteriori target. Di conseguenza, se non otteniamo il messaggio precedente, non è possibile interpretare i risultati ottenuti.

## Risultati del campionamento MCMC

I risultati del campionamento MCMC possono essere estratti usando il metodo `draws` che ritorna un array, ovvero, una matrice multi-dimensionale. In generale, abbiamo molteplici matrici, una per ciascun parametro. Nel caso presente, c'è una sola matrice essendoci un solo parametro. Vengono visualizzate le prime cinque righe delle quattro catene.

```{r}
(post <- fit$draws())
```

L'oggetto `post` è di classe `draws_array`.

```{r}
class(post)
```

## Indici sintetici della distribuzione a posteriori

Indici sintetici della distribuzione a posteriori possono essere calcolati usando le funzioni del pacchetto `posterior`. Ad esempio

```{r}
posterior::summarise_draws(post)
```

L'intervallo di credibilità può essere ottenuto nel modo seguente. Ad esempio, per una probabilità del 95% abbiamo:

```{r}
posterior::summarise_draws(
  post, 
  ~quantile(.x, probs = c(0.025, 0.975))
  )
```


## Visualizzazione

Possiamo visualizzare la distribuzione a posteriori con le funzioni del pacchetto `bayesplot`. 

Ad esempio, l'esame del "mixing" delle catene è fornito dal seguente grafico.

```{r}
bayesplot::mcmc_trace(post, pars = c("theta"))
```

La figura indica che c'è stato un mixing appropriato per le 4 catene.

Un grafico della distribuzione a posteriori è il seguente. Di default, l'area centrale evidenziata corrisponde al 50% dell'area totale.

```{r}
bayesplot::mcmc_areas(post, pars = c("theta"))
```

Se vogliamo evidenziare il 95% dell'area centrale sottesa alla curva, usiamo l'argomento `prob = 0.95`.

```{r}
bayesplot::mcmc_areas(post, pars = c("theta"), prob = 0.95)
```

Sappiamo che, nel caso beta-binomiale, la distribuzione a posteriori deve essere una Beta(25, 17).

```{r}
bayesrules::summarize_beta_binomial(
  alpha = 2, beta = 10, y = 23, n = 30
)
```

Per verificare il risultato ottenuto, sovrapponiamo la curva corrispondente ad una Beta(25, 17) all'approssimazione numerica della distribuzione a posteriori ottenuta da Stan:

```{r}
mcmc_dens(post, pars = "theta") +
  yaxis_text(TRUE) +
  ylab("density") +
  stat_function(fun = dbeta, args = list(shape1 = 25, shape2=17))
```

L'approssimazione numerica della distribuzione a posteriori di $\theta$ fornita da Stan è dunque eccellente.


## Informazioni sulla sessione di lavoro

```{r}
utils::sessionInfo()
```


