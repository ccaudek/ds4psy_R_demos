---
title: "Data science per psicologi - demo 15.01"
author: "Corrado Caudek"
date: "`r format(Sys.Date())`"
output:
  html_document:
    theme: readable
    highlight: pygments
    code_download: true
---

<style type="text/css">
  body{
  font-size: 13pt;
}
code.r{
  font-size: 13pt;
  font-family: 'Inconsolata';
}
.custom-inline {
  font-size: 13pt;
  font-family: 'Inconsolata';
}
</style>


```{r}
suppressPackageStartupMessages({
  library("here")
  library("tidyverse")
  library("scales")
  library("bayesplot")
  library("distrEx")
})

theme_set(bayesplot::theme_default(base_size = 12))
bayesplot::color_scheme_set("gray")
set.seed(84735)

knitr::opts_chunk$set(
  collapse = TRUE,
  tidy = 'styler',
  fig.width = 6,
  fig.asp = 0.618 # 1 / phi
)
```

# Meccanismo generatore dei dati

Consideriamo nuovamente i dati di Zetsche et al. (2019), ovvero 23 successi in 30 prove. Abbiamo visto come il modello generativo per i dati è 

$$
y \sim \mbox{Binom}(n, \theta).
$$

Il parametro ignoto $\theta$ è l'oggetto dell'inferenza.

L'inferenza si svolge mediante l'aggiornamento bayesiano:

$$
p(\theta \mid y) = \frac{p(y \mid \theta) p(\theta)}{\int_{\Theta}p(y \mid \theta) p(\theta) \,\operatorname {d}\!\theta} \quad \theta \in \Theta.
$$

Consideriamo ora un'approssimazione discreta dell'equazione precedente, ovvero il caso in cui considerimo soltanto 20 possibili valori $\theta$:

```{r}
n <- 20
theta <- seq(0, 1, length.out = n)
theta
```

## Distribuzione a priori

Decidiamo di descrivere le nostre opinioni a priori sui valori possibili del parametro $\theta$ mediante una distribuzione Beta di parametri $\alpha = 23.4$ e $\beta = 6.6$.

```{r}
alpha <- 23.4
beta <- 6.6
```

Dato che esaminiamo soltanto 20 valori $\theta$, possiamo discretizzare anche la distribuzione a priori in modo da considerare solo l'ordinata della distribuzione Beta in corrispondenza dei valori $\theta$ presi in considerazione: 

```{r}
fx <- dbeta(theta, alpha, beta)
```

Discretizzando, dobbiamo definire una funzione di massa di probabilità -- ovvero dobbiamo fare in modo da avere una somma unitaria per i valori di probabilità considerati:

```{r}
prior <- fx / sum(fx)
sum(prior)
```

La distribuzione a priori discretizzata diventa dunque:

```{r}
tibble(
  x = theta,
  y = prior
) %>% 
  ggplot(aes(x, y)) +
  geom_point(size = 3) +
  geom_linerange(aes(x=x, ymax = y, ymin = 0)) +
  labs(
    x = "theta",
    y = "P(theta)"
  )
```

# Funzione di verosimiglianza

Per generare la funzione di verosimiglianza dobbiamo utilizzare il modello Binomiale tenendo costante i dati $y = 23, n = 30$, ma variando il valore $\theta$. Per i 20 possibili valori $\theta$ che stiamo considerando, otteniamo:

```{r}
like <- dbinom(23, 30, theta)
like
```

Una rappresentazione grafica è

```{r}
tibble(theta, like) %>% 
  ggplot(aes(x = theta, y = like)) +
  geom_point(size = 3) +
  geom_linerange(aes(x = theta, ymax = like, ymin = 0)) 
```


## Distribuzione a posteriori

La distribuzione a posteriori, $p(\theta \mid y)$, è *proporzionale* al prodotto della distribuzione a priori e della verosimiglianza. 

```{r}
post_distr = like * prior
```

La somma non è 1:

```{r}
sum(post_distr)
```

Dunque, normalizzo:

```{r}
post <- post_distr / sum(post_distr)
sum(post)
```

Una rappresentazione grafica è la seguente:

```{r}
tibble(theta, post) %>% 
  ggplot(aes(x = theta, y = post)) +
  geom_point(size = 3) +
  geom_linerange(aes(x = theta, ymax = post, ymin = 0)) 
```


## Informazioni sulla sessione di lavoro

```{r}
utils::sessionInfo()
```


