---
title: "Data science per psicologi - demo 21.01"
author: "Corrado Caudek"
date: "`r format(Sys.Date())`"
output:
  html_document:
    theme: readable
    highlight: pygments
    code_download: true
---

<style type="text/css">
  body{
  font-size: 13pt;
}
code.r{
  font-size: 13pt;
  font-family: 'Inconsolata';
}
.custom-inline {
  font-size: 13pt;
  font-family: 'Inconsolata';
}
</style>

```{r}
suppressPackageStartupMessages({
  library("here")
  library("tidyverse")
  library("bayesplot")
  library("rstan")
  library("cmdstanr")
  library("bayesrules")
})

rstan_options(auto_write = TRUE) # avoid recompilation of models
options(mc.cores = parallel::detectCores()) # parallelize across all CPUs
Sys.setenv(LOCAL_CPPFLAGS = "-march=native") # improve execution time

theme_set(bayesplot::theme_default(base_size = 12))
bayesplot::color_scheme_set("gray")
set.seed(84735)

knitr::opts_chunk$set(
  collapse = TRUE,
  tidy = 'styler',
  fig.width = 6,
  fig.asp = 0.618 # 1 / phi
)
```

# Sintesi della distribuzione a posteriori

## Esperimento di Milgram

Nell'esperimento di Milgram (1963), 26 partecipanti su 40 hanno inflitto delle scosse elettriche della massima intensit√† ai loro compagni -- non sapevano in realt√† che le scosse fossero solo apparenti, non reali. 

Per analizzare questi dati, nel testo *Bayes rules!* si impone una Beta(1, 10) quale distribuzione a priori su $\theta$ (probabilit√† ignota di infliggere una scossa). 

```{r}
bayesrules::plot_beta(1, 10)
```

Questa scelta della distribuzione a priori ci consente di affrontare il problema all'interno dello schema beta-binomiale. In tali circostanze √® facile trovare la distribuzione a posteriori.  

Sappiamo infatti che la distribuzione a posteriori sar√† una Beta di parametri 27 (ùë¶+ùõº = 26 + 1) e 24 (ùëõ‚àíùë¶+ùõΩ = 30 - 26 + 10).

```{r}
plot_beta_binomial(alpha = 1, beta = 10, y = 26, n = 40)
```

I valori numerici si  ottengono nel modo seguente.

```{r}
summarize_beta_binomial(alpha = 1, beta = 10, y = 26, n = 40)
```

La media della distribuzione Beta √® $\mathbb{E}(\pi) = \alpha / (\alpha + \beta)$.

```{r}
27 / (27 + 24)
```

La moda √®

$$
\mbox{Mo}(\pi) = {\displaystyle {\frac {\alpha -1}{\alpha +\beta -2}}}
$$
ovvero

```{r}
(27 - 1) / (27 + 24 - 2)
```

La varianza √®

$$
\operatorname{var}(X) = \operatorname{E}[(X - \mu)^2] = \frac{\alpha \beta}{(\alpha + \beta)^2(\alpha + \beta + 1)}
$$

ovvero

```{r}
(27 * 24) / ((27 + 24)^2 * (27 + 24 + 1))
```

### Soluzione con Stan

Svolgiamo ora l'analisi con Stan.

I dati nella forma adeguata per essere letti in Stan sono i seguenti.

```{r}
data_list <- list(
  N = 40,
  y = c(rep(1, 26), rep(0, 14))
)
data_list
```

Specifico il modello.

```{r}
model_string <- "
data {
  int<lower=0> N;
  array[N] int<lower=0, upper=1> y;
}
parameters {
  real<lower=0, upper=1> theta;
}
model {
  theta ~ beta(1, 10);
  y ~ bernoulli(theta);
}
"
```

Compilo il modello.

```{r}
writeLines(model_string, con = "code/oneprop_4.stan")
file <- file.path("code", "oneprop_4.stan")
mod <- cmdstan_model(file)
```

Eseguo il campionamento MCMC.

```{r}
fit <- mod$sample(
  data = data_list,
  iter_sampling = 10000L,
  iter_warmup = 2000L,
  seed = 84735,
  chains = 4L,
  refresh = 0,
  thin = 1
)
```

Rappresento graficamente la distribuzione a posteriori.

```{r}
fit_stanfit <- rstan::read_stan_csv(fit$output_files())
posterior <- as.matrix(fit_stanfit)
mcmc_areas(posterior, pars = c("theta"))
```

Una sintesi della distribuzione a posteriori si trova nel modo seguente.

```{r}
fit$summary(c("theta"))
```

Calcolo l'intervallo di credibilit√† al 95%. La scelta dell'95% √® del tutto arbitraria.

```{r}
out <- rstantools::posterior_interval(
  as.matrix(fit_stanfit),
  prob = 0.95
)
out
```

Con l'istruzione seguente trovo l'intervallo di massima densit√† (HDI).

```{r}
stanfit <- rstan::read_stan_csv(fit$output_files())
bayestestR::hdi(stanfit, ci = 0.95)
```

Interpreto l'intervallo di credibilit√† dicendo che, a posteriori, posso quantificare la mia incertezza rispetto al valore ignoto del parametro $\theta$ dicendo che sono sicuri all'89% che il vero valore di tale parametro sia contenuto nell'intervallo [0.40, 0.66]. 

√à anche esprimere la stessa incertezza scegliendo un diverso livello di probabilit√†. Per esempio

```{r}
out <- rstantools::posterior_interval(
  as.matrix(fit_stanfit),
  prob = 0.75
)
out
```

oppure

```{r}
stanfit <- rstan::read_stan_csv(fit$output_files())
bayestestR::hdi(stanfit, ci = 0.75)
```

### Distribuzione a priori non coniugata

Considero ora un esempio in cui non √® possibile usare lo schema beta-binomiale. 

Supponiamo che la distribuzione a priori per $\theta$ sia una $\mathcal{N}(0, 0.12)$.

```{r}
ngrid <- 100
theta_grid <- seq(0, 1, length.out = ngrid) 
prior <- dnorm(theta_grid, mean = 0, sd = 0.12)
df <- data.frame(
  theta_grid = theta_grid, prior = prior
)

plot(df$theta_grid, df$prior, type = 'l')
```

Con una $\mathcal{N}(0, 0.12)$, le credenze descritte dalla distribuzione a priori sono molto simili a quelle descritte da una Beta(1, 10), anche se non identiche.

Tutte le altre caratteristiche del problema restano uguali al caso discusso sopra.

Specifico dunque il modello in Stan.

```{r}
model2_string <- "
data {
  int<lower=0> N;
  array[N] int<lower=0, upper=1> y;
}
parameters {
  real<lower=0, upper=1> theta;
}
model {
  theta ~ normal(0, 0.12);
  y ~ bernoulli(theta);
}
"
```

Compilo il modello.

```{r}
writeLines(model2_string, con = "code/oneprop_5.stan")
file2 <- file.path("code", "oneprop_5.stan")
mod2 <- cmdstan_model(file2)
```

Eseguo il campionamento MCMC.

```{r}
fit2 <- mod2$sample(
  data = data_list,
  iter_sampling = 10000L,
  iter_warmup = 2000L,
  seed = 84735,
  chains = 4L,
  refresh = 0
)
```

Rappresento graficamente la distribuzione a posteriori.

```{r}
fit2_stanfit <- rstan::read_stan_csv(fit2$output_files())
posterior2 <- as.matrix(fit2_stanfit)
mcmc_areas(posterior2, pars = c("theta"))
```

Una sintesi della distribuzione a posteriori si trova nel modo seguente.

```{r}
fit2$summary(c("theta"))
```

Calcolo l'intervallo di credibilit√† al 89%. La scelta dell'89% √® del tutto arbitraria.

```{r}
out2 <- rstantools::posterior_interval(
  as.matrix(fit2_stanfit),
  prob = 0.95
)
out2
```

L'intervallo a densit√† a posteriori pi√π alta al 95% √® praticamente identico a quello trovato in precedenza.

```{r}
stanfit2 <- rstan::read_stan_csv(fit2$output_files())
bayestestR::hdi(stanfit2, ci = 0.95)
```

## Considerazioni conclusive {-}

A parte gli esercizi didattici qui forniti, la scelta della distribuzione a priori deve in qualche modo essere motivata. Se non disponiamo di informazioni che vogliamo racchiudere nella distribuzione a priori, la scelta migliore √® quella di usare una distribuzione a priori *debolmente informativa*.  Nel caso dell'esempio presente, io userei una Beta(2, 2).


## Informazioni sulla sessione di lavoro

```{r}
utils::sessionInfo()
```


