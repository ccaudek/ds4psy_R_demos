---
title: "Data science per psicologi - demo 13.03"
author: "Corrado Caudek"
date: "`r format(Sys.Date())`"
output:
  html_document:
    theme: readable
    highlight: pygments
    code_download: true
---

<style type="text/css">
  body{
  font-size: 13pt;
}
code.r{
  font-size: 13pt;
  font-family: 'Inconsolata';
}
.custom-inline {
  font-size: 13pt;
  font-family: 'Inconsolata';
}
</style>

```{r}
suppressPackageStartupMessages({
  library("here")
  library("tidyverse")
  library("bayesplot")
})

theme_set(bayesplot::theme_default(base_size = 12))
bayesplot::color_scheme_set("gray")
set.seed(84735)

knitr::opts_chunk$set(
  collapse = TRUE,
  # tidy = 'styler',
  fig.width = 6,
  fig.asp = 0.618 # 1 / phi
)
```

# Funzione beta

La funzione beta di Eulero, indicata con $\mbox{B}(\alpha, \beta)$, è una funzione matematica, **non** è una distribuzione di densità. La funzione beta dipende da due parametri, $\alpha$ e $\beta$, ed è definita nel modo seguente:

$$
\mbox{beta}(\alpha, \beta) = \frac{\gamma(\alpha) \gamma(\beta)}{\gamma(\alpha + \beta)},
$$

con $\gamma(x) = (x-1)!$. 

Ad esempio, fissando i parametri ai valori seguenti

```{r}
alpha <- 2
beta <- 4
```

la funzione $\mbox{B}(\alpha, \beta)$ assume il valore seguente:

```{r}
beta(alpha, beta)
```

Replichiamo il risultato precedente svolgendo i calcoli in modo esplicito:

```{r}
gamma(alpha) * gamma(beta) / gamma(alpha + beta)
```

ovvero

```{r}
(factorial(alpha - 1) * factorial(beta - 1)) / (factorial(alpha + beta - 1))
```


## Distribuzione beta

Si dice che una variabile casuale continua $\pi \in [0, 1]$ segue la distribuzione Beta se la sua densità di probabilità di parametri $\alpha$ e $\beta$ è uguale a

$$
\mbox{Beta}(\alpha, \beta) = \frac{1}{\mbox{B}(\alpha, \beta)} \pi^{\alpha-1}\pi^{\beta-1},
$$

dove $\mbox{B}(\alpha, \beta)$ è la funzione beta.

Per fare un esempio, consideriamo la distribuzione Beta di parametri $\alpha = 2$ e $\beta = 4$. Una rappresentazione grafica di tale funzione di densità si ottiene nel modo seguente:

```{r}
tibble(
  x = seq(0, 1, length.out = 1e3)
) %>% 
  mutate(
    y = dbeta(x, 2, 4)
) %>% 
  ggplot(aes(x, y)) +
  geom_line()
```

ovvero

```{r}
beta_fnc <- function(alpha, beta) {
  (factorial(alpha - 1) * factorial(beta - 1)) / (factorial(alpha + beta - 1))
}

beta_dens <- function(alpha, beta, pi) {
  (1 / beta_fnc(alpha, beta)) * (pi^(alpha-1) * (1 - pi)^(beta -1))
}

tibble(
  x = seq(0, 1, length.out = 1e3)
) %>% 
  mutate(
    y = beta_dens(2, 4, x)
) %>% 
  ggplot(aes(x, y)) +
  geom_line()
```

Lo stesso risultato si ottiene usando la funzione `plot_beta()` del pacchetto `bayesrules`:

```{r}
bayesrules::plot_beta(alpha, beta)
```

L'area sottesa alla funzione di densità è

```{r}
integrand <- function(p) {
 1 / beta_fnc(alpha, beta) * p^{alpha - 1} * (1 - p)^{beta - 1}
}

integrate(integrand, lower = 0, upper = 1)
```

Dato che il kernel della distribuzione beta, ovvero $\pi^{\alpha-1}\pi^{\beta-1}$, è moltiplicato per $1/\mbox{B}(\alpha, \beta)$, questo significa che $\mbox{B}(\alpha, \beta)$ viene utilizzata per normalizzare $\pi^{\alpha-1}\pi^{\beta-1}$. In altre parole, il valore della funzione beta

```{r}
beta(alpha, beta)
```

è uguale all'area del kernel della distribuzione Beta:

```{r}
integrand <- function(p) {
 p^{alpha - 1} * (1 - p)^{beta - 1}
}
integrate(integrand, lower = 0, upper = 1)
```

La funzione $\mbox{B}(\alpha, \beta)$ fornisce dunque una costante di normalizzazione per il kernel della distribuzione Beta.

### Valore atteso

Calcoliamo il valore atteso di una variabile casuale $\pi$ che segue una  distribuzione Beta di parametri $\alpha = 2$ e $\beta = 4$:

$$
\mathbb{E}(\pi) = \frac{\alpha}{\alpha + \beta}
$$

```{r}
ex <- alpha / (alpha + beta)
ex
```

ovvero

$$
\mathbb{E}(\pi) = \int_0^1 \pi \, f(\pi) \,\operatorname {d}\!\pi .
$$

laddove $f(\pi)$ è la funzione di densità Beta. Per i dati dell'esempio abbiamo:

```{r}
integrand <- function(p) {
 p * 1 / beta_fnc(alpha, beta) * p^{alpha - 1} * (1 - p)^{beta - 1}
}
integrate(integrand, lower = 0, upper = 1)
```


### Varianza

La varianza è 

$$
\mbox{Var}(\pi) = \frac{\alpha \beta}{(\alpha + \beta)^2 (\alpha + \beta + 1)}
$$

```{r}
var_beta_distr <- function(a, b) {
  (a * b) / ((a + b)^2 * (a + b + 1))
}
var_beta_distr(alpha, beta)
```

ovvero

$$
\mathbb{V}(\pi) = \int_0^1 \big(\pi - \mathbb{E}(\pi)\big)^2 f(\pi)  \,\operatorname {d}\!\pi ,
$$

laddove $f(\pi)$ è la funzione di densità Beta. Per i dati dell'esempio abbiamo:

```{r}
integrand <- function(p) {
 (p - ex)^2 * 1 / beta_fnc(alpha, beta) * p^{alpha - 1}*(1 - p)^{beta - 1}
}
integrate(integrand, lower = 0, upper = 1)
```

In maniera equivalente possiamo usare la funzione $\mathsf{R}$ `dbeta()`:

```{r}
integrand <- function(p) {
 (p - ex)^2 * dbeta(p, alpha, beta)
}
integrate(integrand, lower = 0, upper = 1)
```

Gli stessi risultati si ottengono con `summarize_beta()`:

```{r}
bayesrules::summarize_beta(alpha, beta)
```

## Interpretazione

Iniziamo a calcolare la *mediana* della distribuzione Beta. Un valore **approssimativo** della mediana è dato da:

$$
\mbox{Md} \approx \frac{\alpha - \frac{1}{3}}{\alpha + \beta - \frac{2}{3}}
$$

Implementiamo questa funzione in $\mathsf{R}$:

```{r}
median_beta <- function(a, b) {
  (a - 1/3) / (a + b - 2/3)
}
```

Per il caso dell'esempio in discussione, otteniamo:

```{r}
med <- median_beta(alpha, beta)
med
```

Nel caso di una funzione di densità, che interpretazione può essere assegnata alla mediana?

Nel caso delle variabili casuali discrete, abbiamo visto che la media coincide con il centro di massa della distribuzione:

```{r}
x <- runif(10, 1, 100) %>% round()
x
```

```{r}
x - mean(x)
```

```{r}
(x - mean(x)) %>% sum()
```

Questa idea può essere estesa al caso delle variabili casuali continue. Nel caso di una funzione di densità $p(x)$, però, è la mediana, $x_m$, che divide l'area sottesa alla curva di densità di probabilità in due porzioni uguali:

$$
\int_{-\infty}^{x_m} p(x) \,\operatorname {d}\!x = \int_{x_m}^{-\infty} p(x) \,\operatorname {d}\!x = \frac{1}{2}.
$$

Segue da tale definizione che la mediana è il valore $x$ per il quale la distribuzione cumulativa soddisfa

$$
F(x_m) = \frac{1}{2}.
$$

Verifichiamo questa affermazione nel caso della distribuzione Beta in esame:

```{r}
integrand <- function(p) {
  1 / beta_fnc(alpha, beta) * p^{alpha - 1} * (1 - p)^{beta - 1}
}
integrate(integrand, lower = 0, upper = median_beta(alpha, beta))
integrate(integrand, lower = median_beta(alpha, beta), upper = 1)
```


Se facciamo riferimento al valore atteso, invece, otteniamo

```{r}
integrand <- function(p) {
  1 / beta_fnc(alpha, beta) * p^{alpha - 1} * (1 - p)^{beta - 1}
}
integrate(integrand, lower = 0, upper = 1/3)
integrate(integrand, lower = 1/3, upper = 1)
```


Al valore atteso e alla varianza possiamo invece assegnare l'interpretazione usuale. Se consideriamo un enorme numero di realizzazioni della variabiel casuale $\pi$

```{r}
x <- rbeta(1e6, alpha, beta)
```

allora la media di tali valori approssima $\mathbb{E}(\pi)$ 

```{r}
mean(x)
```

e la varianza di tali valori approssima $\mathbb{V}(\pi)$ 

```{r}
var(x)
```

## Esercizio 1

Supponiamo di avere a disposizione i voti $X$ degli studenti in un insegnamento universitario. Tali voti sono espressi come proporzioni, ovvero, sono valori compresi nell'intervallo $[0, 1]$. Supponiamo che la distribuzione dei voti sia bene descritta da una distribuzione Beta: $X ∼ \mbox{Beta}(\alpha = 8.28, \beta = 3.16)$. Ci chiediamo: qual è la probabilità che uno studente sia al di sotto della media (cioè delle aspettative)?

Per rispondere a questa domanda dobbiamo fare due cose:

- calcolare la media della distribuzione,
- calcolare la probabilità che la variabile casuale (voto dello studente) assuma un valore inferiore al valore atteso.

Il valore atteso della variabile casuale $X$ è

```{r}
alpha <- 8.28
beta <- 3.16
ev <- alpha / (alpha + beta)
ev
```

Ora dobbiamo calcolare $P(X < \mathbb{E}(X))$. Per fare questo possiamo usare la funzione `pbeta()`, la quale restituisce il valore della funzione di ripartizione in corrispondenza del quantile indicato -- ovvero, l'area sottesa alla funzione di densità nella coda di sinistra da $-\infty$ fino al quantile indicato:

```{r}
pbeta(ev, alpha, beta)
```

## Esercizio 2

Per i dati dell'esempio precedente, si crei una rappresentazione grafica della distribuzione Beta in esame.

```{r}
bayesrules::plot_beta(alpha, beta)
```

## Esercizio 3

Per i dati dell'esempio precedente, si trovi il voto $X$ tale per cui solo il 10% degli studenti ha ottenuto un risultato migliore.

```{r}
qbeta(0.9, alpha, beta)
```

## Informazioni sulla sessione di lavoro

```{r}
utils::sessionInfo()
```


