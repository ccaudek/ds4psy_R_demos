---
title: "Data science per psicologi - demo 18.01"
author: "Corrado Caudek"
date: "`r format(Sys.Date())`"
output:
  html_document:
    theme: readable
    highlight: pygments
    code_download: true
---

<style type="text/css">
  body{
  font-size: 13pt;
}
code.r{
  font-size: 13pt;
  font-family: 'Inconsolata';
}
.custom-inline {
  font-size: 13pt;
  font-family: 'Inconsolata';
}
</style>

```{r}
suppressPackageStartupMessages({
  library("here")
  library("tidyverse")
  library("bayesplot")
})

theme_set(bayesplot::theme_default(base_size = 12))
bayesplot::color_scheme_set("gray")
set.seed(84735)

knitr::opts_chunk$set(
  collapse = TRUE,
  tidy = 'styler',
  fig.width = 6,
  fig.asp = 0.618 # 1 / phi
)
```

# L'algoritmo di Metropolis

```{r}
likelihood <- function(param, x = 23, N = 30) { 
   dbinom(x, N, param)
}
```

```{r}
prior <- function(param, alpha = 2, beta = 10) { 
   dbeta(param, alpha, beta)
}
```

```{r}
posterior <- function(param) { 
   likelihood(param) * prior(param)
}
```

```{r}
proposal_distribution <- function(param) {
  # creo la condizione che forza l'entrata nel ciclo while()
  res <- -1
  # resto all'interno del ciclo finché res è minore di 0 o maggiore di 1
  while (res < 0 | res > 1) {
    # quando res è un numero in [0, 1] viene falsificata la condizione
    # del ciclo while() e si esce dal ciclo
    res <- rnorm(1, mean = param, sd = 0.9)
  }
  # res è dunque un numero a caso, compreso tra 0 e 1, estratto da una gaussiana
  # standardizzata -- il che significa che è più probabile ottenere valori 
  # nell'intorno di 0 che valori appena minori di 1 o appena maggiori di -1.
  res
}
```

```{r}
# Il primo punto della catena è un valore a caso tra 0 e 1.
startvalue <- runif(1, 0, 1)
# La catena viene generata nel modo seguente.
metropolis <- function(startvalue, iterations) {
  # Creo un contenitore vuoto dove salvare i risultati.
  chain <- vector(length = iterations + 1)
  # Inizializzo la catena con startvalue.
  chain[1] <- startvalue
  # Ripeto le istruzioni seguenti un numero di volte pari a iterations.
  for (i in 1:iterations) {
    # Ottengo un valore molto simile al valore corrente della catena.
    proposal <- proposal_distribution(chain[i])
    # Calcolo il rapporto tra la densità a posteriori del valore proposto e
    # la densità a posteriori del valore corrente.
    prob_move <- posterior(proposal) / posterior(chain[i])
    # Se la densità a posteriori del valore proposto è maggiore di quella del
    # valore corrente, allora accetto la proposta: la catena si muove dal valore
    # corrente al valore proposto (che diventa il valore corrente della 
    # seguente iterazione). Altrimenti il valore proposto viene accettato solo 
    # in una proporzione di casi uguale al rapporto tra densità a posteriori
    # del valore proposto e la densità a posteriori del valore corrente.
    if (prob_move > 1) {
      chain[i + 1] <- proposal
    } else {
      r <- runif(1, 0, 1)
      chain[i + 1] <- ifelse(r < prob_move, proposal, chain[i])
    }
  }
  chain
}
```


```{r}
prob <- 0.3
nrep <- 1e4
sim <- rep(NA, nrep)
for (i in 1:nrep) {
  r <- runif(1, 0, 1)
  sim[i] <- ifelse(r < prob, 1, 0)
}
mean(sim)
```

Si accetta il valore proposto di $\theta$ con una probabilità uguale a `prob_move`. Di conseguenza, la frequenza dei valori nella catena sarà proporzionale alla densità della distribuzione a posteriori.

```{r}
set.seed(84735)
startvalue <- runif(1, 0, 1)
niter <- 1e5
chain <- metropolis(startvalue, niter)
```

Calcolo l'accettanza.

```{r}
burnin <- niter / 2
acceptance <- 1 - mean(duplicated(chain[-(1:burnin)])) 
acceptance
```

Calcolo la media dell'approssimazione numerica della distribuzione a posteriori.

```{r}
mean(chain[-(1:burnin)])
```

Calcolo la deviazione standard dell'approssimazione numerica della distribuzione a posteriori.

```{r}
sd(chain[-(1:burnin)])
```

Confronto i risultati ottenuti con l'algoritmo di Metropolis con quelli ottenuti per via analitica.


```{r}
bayesrules:::summarize_beta_binomial(
  alpha = 2, beta = 10, y = 23, n = 30
)
```

Creo un kernel density plot per la distribuzione a posteriori.


```{r}
plot(density(chain[-(1:burnin)]))
```

La distribuzione a posteriori è una Beta(25, 17). La figura seguente rappresenta un istogramma dei valori $\theta$ prodotti dall'algoritmo di Metropolis a cui è stata sovrapposta la distribuzione a posteriori ottenuta per via analitica, ovvero una Beta(25, 17). 

```{r}
df <- tibble(x = chain[-(1:burnin)])

df %>%
  ggplot(aes(x = x)) +
  geom_histogram(
    mapping = aes(x = x, y = ..density..), 
    fill = "steelblue", 
    colour = "black", 
    binwidth = 0.01
  ) +
  stat_function(fun = dbeta, args = list(shape1 = 25, shape2 = 17)) +
  labs(
    x = "theta",
    y = "Density"
  )
```

Si vede che la catena converge alla corretta distribuzione a posteriori.

## Versione 2

È equivalente scrivere l'algoritmo di Metropolis nel modo seguente.

```{r}
startvalue <- runif(1, 0, 1)
metropolis <- function(startvalue, iterations) {
  chain <- vector(length = iterations + 1)
  chain[1] <- startvalue
  for (i in 1:iterations) {
    proposal <- proposal_distribution(chain[i])
    prob_move <- posterior(proposal) / posterior(chain[i])
    chain[i + 1] <- 
      ifelse(runif(1) < prob_move, proposal, chain[i])
  }
  chain
}
```

```{r}
set.seed(84735)
startvalue <- runif(1, 0, 1)
niter <- 1e5
chain <- metropolis(startvalue, niter)

burnin <- niter / 2
acceptance <- 1 - mean(duplicated(chain[-(1:burnin)])) 
acceptance
```

```{r}
mean(chain[-(1:burnin)])
```

```{r}
sd(chain[-(1:burnin)])
```

## Informazioni sulla sessione di lavoro

```{r}
utils::sessionInfo()
```


